# INFO591
My name is Justin. I'm software engineer. I majored in computer science during undergraduate, and now that I'm want to sharp my analytics skill, which I've decided to pursue data science as my graduate major. My goal for this class is gaining new perspectives on data and digital stewardship.

"Challenges in Machine Learning" under [DataChallenges](http://www.chalearn.org) caught caught my attention. The datasets provided by ChaLearn are typically collected for specific purposes, often to address research questions or challenges in machine learning and AI. These datasets serve as benchmarks for evaluating algorithms, models, and techniques in various domains. The specific datasets available on the ChaLearn website may vary, but they could cover a wide range of topics such as computer vision, natural language processing, recommendation systems, or other AI-related applications. For example, ChaLearn might collect datasets for tasks like image classification, object detection, sentiment analysis, or predictive modeling. Researchers, data scientists, and machine learning practitioners can utilize these datasets to develop and test new algorithms, compare their models against others, or evaluate the performance of their AI systems. The datasets provided by ChaLearn often come with benchmarking metrics, evaluation protocols, and guidelines to ensure fair comparisons and consistent evaluation practices.

Here's the metadata I found from "Challenges in Machine Learning":
* title: Challenges in Machine Learning
* homepage: http://www.chalearn.org/
* category: DataChallengeses to any papers, articles, or research work related to the dataset.

Depend the changellenge, the dataset can be found "Challenges" where "data available" is clickable.

The first topic that i explored was machine-learning. I looked at the [TensorFlow](https://github.com/tensorflow/tensorflow). This is the official GitHub repository for TensorFlow, an open-source machine learning framework developed by Google. TensorFlow is a widely used framework for building and deploying machine learning models, especially deep learning models.The repository hosts the source code and documentation for TensorFlow, making it the central hub for the project's development and collaboration. It serves as a central hub for TensorFlow's development, collaboration, and community engagement. It houses the core codebase, documentation, examples, and resources necessary for working with TensorFlow. Overall, ensorFlow provides extensive support for building and training neural networks, making it particularly suitable for deep learning applications. It offers a high-level API called Keras that simplifies the process of building deep learning models.

The second topic that I explored was sorting-algorithms. I look at the [TheAlgorithms](https://github.com/TheAlgorithms). It is an open-source collection of algorithms implemented in various programming languages. TheAlgorithms repository aims to provide a centralized collection of algorithms, data structures, and problem-solving techniques implemented in different programming languages.It covers a wide range of algorithms, including sorting, searching, graph algorithms, dynamic programming, and more. The repository is organized into directories based on the programming language used for implementation. Each directory contains multiple files, with each file representing an algorithm or data structure implementation. The implementations often include comments and explanations to enhance understanding and promote learning. Machine learning often requires preprocessing and manipulation of data before feeding it to learning algorithms. The repository's implementations of algorithms and data structures can be useful in data preprocessing tasks, such as sorting, searching, or working with graphs, which are common in preparing data for machine learning. ALso, The repository includes implementations of fundamental algorithms, such as various optimization algorithms (e.g., gradient descent), mathematical algorithms (e.g., linear algebra operations), and statistical algorithms such as sorting, searching, and sampling. These algorithms serve as building blocks for developing and implementing machine learning models.

Overall, GitHub is primarily a version control system, enabling developers and researchers to track changes and manage different versions of their projects and datasets. This feature allows for easy collaboration, as multiple contributors can work on the same project simultaneously, make changes, and merge their modifications seamlessly. Additionally, GitHub serves as a centralized platform for sharing code and data with the community. Researchers and developers can upload their datasets, scripts, and analysis code to GitHub repositories, making them accessible to others for reuse, replication, and further collaboration.
